2016-10-05 16:54:30,490 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = agent2/199.60.17.226
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.0
STARTUP_MSG:   classpath = /home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-auth-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf; compiled by 'jenkins' on 2015-04-10T18:40Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2016-10-05 16:54:30,501 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2016-10-05 16:54:31,536 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2016-10-05 16:54:31,538 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2016-10-05 16:54:31,538 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2016-10-05 16:54:31,538 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2016-10-05 16:54:31,539 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2016-10-05 16:54:31,540 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2016-10-05 16:54:31,563 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2016-10-05 16:54:31,563 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2016-10-05 16:54:31,604 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-10-05 16:54:31,678 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-10-05 16:54:31,678 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2016-10-05 16:54:31,739 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2016-10-05 16:54:31,741 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2016-10-05 16:54:31,742 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2016-10-05 16:54:31,767 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2016-10-05 16:54:31,793 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2016-10-05 16:54:31,793 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2016-10-05 16:54:31,875 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@36954f73
2016-10-05 16:54:31,875 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2016-10-05 16:54:31,875 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2016-10-05 16:54:31,875 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2016-10-05 16:54:31,882 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2016-10-05 16:54:31,920 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-10-05 16:54:31,939 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 38959
2016-10-05 16:54:32,002 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2016-10-05 16:54:32,002 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2016-10-05 16:54:32,002 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-10-05 16:54:32,002 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 38959: starting
2016-10-05 16:54:32,023 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : agent2:38959
2016-10-05 16:54:32,032 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-10-05 16:54:32,033 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2016-10-05 16:54:32,037 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2016-10-05 16:54:32,037 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-10-05 16:54:32,037 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2016-10-05 16:54:32,038 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2016-10-05 16:54:32,051 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2016-10-05 16:54:32,075 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2016-10-05 16:54:32,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at agent2/199.60.17.226:38959
2016-10-05 16:54:32,077 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2016-10-05 16:54:32,078 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2016-10-05 16:54:32,158 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-10-05 16:54:32,166 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-10-05 16:54:32,172 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2016-10-05 16:54:32,179 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-10-05 16:54:32,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2016-10-05 16:54:32,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-10-05 16:54:32,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-10-05 16:54:32,185 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2016-10-05 16:54:32,185 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2016-10-05 16:54:32,194 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2016-10-05 16:54:32,194 INFO org.mortbay.log: jetty-6.1.26
2016-10-05 16:54:32,223 INFO org.mortbay.log: Extract jar:file:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2016-10-05 16:54:32,435 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2016-10-05 16:54:32,435 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2016-10-05 16:54:32,768 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2016-10-05 16:54:32,776 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031
2016-10-05 16:54:32,805 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2016-10-05 16:54:32,810 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2016-10-05 16:54:33,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:34,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:35,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:36,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:37,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:38,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:39,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:40,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:41,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:54:42,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:13,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:14,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:15,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:16,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:17,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:18,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:19,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:20,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:21,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:22,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:53,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:54,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:55,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:56,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:57,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:58,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:55:59,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:00,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:01,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:02,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:33,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:34,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:35,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:36,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:37,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:38,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:39,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:40,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:41,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:56:42,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:13,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:14,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:15,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:16,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:17,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:18,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:19,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:20,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:21,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:22,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:53,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:54,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:55,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:56,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:57,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:58,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:57:59,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:00,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:01,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:02,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:33,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:34,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:35,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:36,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:37,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:38,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:39,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:40,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:41,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:58:42,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:13,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:14,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:15,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:16,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:17,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:18,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:19,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:20,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:21,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:22,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:53,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:54,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:55,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:56,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:57,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:58,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 16:59:59,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:00,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:01,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:02,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:33,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:34,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:35,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:36,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:37,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:38,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:39,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:40,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:41,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:00:42,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:13,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:14,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:15,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:16,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:17,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:18,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:19,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:20,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:21,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:22,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:53,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:54,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:55,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:56,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:57,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:58,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:01:59,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:00,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:01,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:02,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:33,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:34,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:35,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:36,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:37,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:38,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:39,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:40,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:42,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:02:43,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:14,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:15,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:16,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:17,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:18,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:19,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:20,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:21,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:22,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:23,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:54,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:55,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:56,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:57,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:58,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:03:59,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:00,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:01,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:02,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:03,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:34,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:35,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:36,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:37,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:38,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:39,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:40,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:41,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:42,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:04:43,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:14,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:15,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:16,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:17,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:18,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:19,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:20,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:21,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:22,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:23,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:54,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:55,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:56,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:57,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:58,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:05:59,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:00,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:01,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:02,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:03,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:34,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:35,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:36,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:37,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:38,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:39,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:40,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:41,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:42,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:06:43,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:14,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:15,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:16,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:17,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:18,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:19,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:20,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:21,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:22,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:23,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:54,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:55,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:56,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:57,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:58,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:07:59,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:00,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:01,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:02,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:03,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:34,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:35,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:36,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:37,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:38,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:39,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:40,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:41,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:42,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:08:43,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:14,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:15,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:16,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:17,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:18,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:19,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:20,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:21,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:22,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:23,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:54,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:55,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:56,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:57,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:58,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:09:59,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:00,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:01,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:02,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:03,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:34,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:35,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:36,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:37,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:38,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:39,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:40,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:41,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:42,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:10:43,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:14,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:15,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:16,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:17,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:18,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:19,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:20,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:21,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:22,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:23,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:54,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:55,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:56,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:57,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:58,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:11:59,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:00,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:01,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:02,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:03,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:34,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:35,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:36,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:37,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:38,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:39,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:40,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:41,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:42,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:12:43,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:14,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:15,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:16,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:17,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:18,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:19,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:20,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:21,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:22,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:23,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:54,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:55,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:56,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:57,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:58,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:13:59,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:00,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:01,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:02,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:03,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:34,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:35,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:36,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:37,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:38,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:39,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:40,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:41,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:42,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:43,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8031. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2016-10-05 17:14:43,266 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Unexpected error starting NodeStatusUpdater
java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy27.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy28.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:262)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:196)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStart(NodeManager.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:464)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:511)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 18 more
2016-10-05 17:14:43,268 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl failed in state STARTED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:202)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStart(NodeManager.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:464)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:511)
Caused by: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy27.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy28.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:262)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:196)
	... 6 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 18 more
2016-10-05 17:14:43,270 INFO org.apache.hadoop.service.AbstractService: Service NodeManager failed in state STARTED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:202)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStart(NodeManager.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:464)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:511)
Caused by: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy27.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy28.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:262)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:196)
	... 6 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 18 more
2016-10-05 17:14:43,273 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2016-10-05 17:14:43,374 INFO org.apache.hadoop.ipc.Server: Stopping server on 38959
2016-10-05 17:14:43,375 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl is interrupted. Exiting.
2016-10-05 17:14:43,376 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2016-10-05 17:14:43,376 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 38959
2016-10-05 17:14:43,409 INFO org.apache.hadoop.ipc.Server: Stopping server on 8040
2016-10-05 17:14:43,409 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8040
2016-10-05 17:14:43,410 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Public cache exiting
2016-10-05 17:14:43,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NodeManager metrics system...
2016-10-05 17:14:43,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system stopped.
2016-10-05 17:14:43,411 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system shutdown complete.
2016-10-05 17:14:43,411 FATAL org.apache.hadoop.yarn.server.nodemanager.NodeManager: Error starting NodeManager
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:202)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:120)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceStart(NodeManager.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:464)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:511)
Caused by: java.net.ConnectException: Call From agent2/199.60.17.226 to 0.0.0.0:8031 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor7.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy27.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:68)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy28.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:262)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.serviceStart(NodeStatusUpdaterImpl.java:196)
	... 6 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1446)
	... 18 more
2016-10-05 17:14:43,413 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2016-10-05 17:14:43,418 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at agent2/199.60.17.226
************************************************************/
2016-10-05 17:44:23,343 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NodeManager
STARTUP_MSG:   host = agent2/199.60.17.226
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.0
STARTUP_MSG:   classpath = /home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-auth-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/etc/hadoop/nm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf; compiled by 'jenkins' on 2015-04-10T18:40Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2016-10-05 17:44:23,357 INFO org.apache.hadoop.yarn.server.nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]
2016-10-05 17:44:24,888 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher
2016-10-05 17:44:24,890 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher
2016-10-05 17:44:24,891 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
2016-10-05 17:44:24,891 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices
2016-10-05 17:44:24,892 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl
2016-10-05 17:44:24,893 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
2016-10-05 17:44:24,928 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl
2016-10-05 17:44:24,928 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager
2016-10-05 17:44:24,989 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-10-05 17:44:25,097 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-10-05 17:44:25,098 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NodeManager metrics system started
2016-10-05 17:44:25,134 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler
2016-10-05 17:44:25,136 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService
2016-10-05 17:44:25,137 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: per directory file limit = 8192
2016-10-05 17:44:25,161 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: usercache path : file:/tmp/hadoop-cloud/nm-local-dir/usercache_DEL_1475714665141
2016-10-05 17:44:25,206 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker
2016-10-05 17:44:25,228 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2016-10-05 17:44:25,228 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, "mapreduce_shuffle"
2016-10-05 17:44:25,291 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@81316dd
2016-10-05 17:44:25,291 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null
2016-10-05 17:44:25,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Physical memory check enabled: true
2016-10-05 17:44:25,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Virtual memory check enabled: true
2016-10-05 17:44:25,298 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8
2016-10-05 17:44:25,331 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-10-05 17:44:25,349 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 38523
2016-10-05 17:44:25,399 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server
2016-10-05 17:44:25,399 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Blocking new container-requests as container manager rpc server is still starting.
2016-10-05 17:44:25,399 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-10-05 17:44:25,399 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 38523: starting
2016-10-05 17:44:25,407 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Updating node address : agent2:38523
2016-10-05 17:44:25,414 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-10-05 17:44:25,415 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8040
2016-10-05 17:44:25,418 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server
2016-10-05 17:44:25,419 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-10-05 17:44:25,419 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8040: starting
2016-10-05 17:44:25,420 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer started on port 8040
2016-10-05 17:44:25,432 INFO org.apache.hadoop.mapred.IndexCache: IndexCache created with max memory = 10485760
2016-10-05 17:44:25,445 INFO org.apache.hadoop.mapred.ShuffleHandler: httpshuffle listening on port 13562
2016-10-05 17:44:25,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager started at agent2/199.60.17.226:38523
2016-10-05 17:44:25,447 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0
2016-10-05 17:44:25,448 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042
2016-10-05 17:44:25,519 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-10-05 17:44:25,527 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-10-05 17:44:25,531 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined
2016-10-05 17:44:25,538 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-10-05 17:44:25,540 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node
2016-10-05 17:44:25,540 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-10-05 17:44:25,540 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-10-05 17:44:25,543 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /node/*
2016-10-05 17:44:25,544 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2016-10-05 17:44:25,552 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8042
2016-10-05 17:44:25,552 INFO org.mortbay.log: jetty-6.1.26
2016-10-05 17:44:25,578 INFO org.mortbay.log: Extract jar:file:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_8042_node____19tj0x/webapp
2016-10-05 17:44:25,785 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2016-10-05 17:44:25,785 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 8042
2016-10-05 17:44:26,100 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2016-10-05 17:44:26,108 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at master1/199.60.17.185:8031
2016-10-05 17:44:26,137 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []
2016-10-05 17:44:26,142 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]
2016-10-05 17:44:26,201 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id -1165677709
2016-10-05 17:44:26,204 INFO org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 135204589
2016-10-05 17:44:26,205 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as agent2:38523 with total resource of <memory:8192, vCores:8>
2016-10-05 17:44:26,205 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Notifying ContainerManager to unblock new container-requests
2016-10-05 17:45:37,686 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,688 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,689 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,691 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,692 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,694 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,696 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,698 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:37,809 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000005 by user cloud
2016-10-05 17:45:37,809 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000007 by user cloud
2016-10-05 17:45:37,809 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000002 by user cloud
2016-10-05 17:45:37,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000008 by user cloud
2016-10-05 17:45:37,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000004 by user cloud
2016-10-05 17:45:37,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000006 by user cloud
2016-10-05 17:45:37,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000003 by user cloud
2016-10-05 17:45:37,812 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Start request for container_1475714661937_0001_01_000009 by user cloud
2016-10-05 17:45:37,839 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Creating a new application reference for app application_1475714661937_0001
2016-10-05 17:45:37,842 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000003 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000009 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000007 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000004 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000002 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000008 to application application_1475714661937_0001
2016-10-05 17:45:37,843 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000006 to application application_1475714661937_0001
2016-10-05 17:45:37,845 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000003
2016-10-05 17:45:37,847 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application application_1475714661937_0001 transitioned from NEW to INITING
2016-10-05 17:45:37,847 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Adding container_1475714661937_0001_01_000005 to application application_1475714661937_0001
2016-10-05 17:45:37,845 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000005
2016-10-05 17:45:37,849 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000008
2016-10-05 17:45:37,849 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000006
2016-10-05 17:45:37,849 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000002
2016-10-05 17:45:37,849 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000004
2016-10-05 17:45:37,850 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000007
2016-10-05 17:45:37,850 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Start Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000009
2016-10-05 17:45:37,853 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application application_1475714661937_0001 transitioned from INITING to RUNNING
2016-10-05 17:45:37,864 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,869 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,869 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,870 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,871 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,871 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from NEW to LOCALIZING
2016-10-05 17:45:37,871 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,876 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,876 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,878 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,888 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://master1:9000/tmp/hadoop-yarn/staging/cloud/.staging/job_1475714661937_0001/job.jar transitioned from INIT to DOWNLOADING
2016-10-05 17:45:37,888 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://master1:9000/tmp/hadoop-yarn/staging/cloud/.staging/job_1475714661937_0001/job.xml transitioned from INIT to DOWNLOADING
2016-10-05 17:45:37,888 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,888 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,889 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,889 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,889 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,890 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,890 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,890 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,890 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,891 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_INIT for appId application_1475714661937_0001
2016-10-05 17:45:37,891 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got APPLICATION_INIT for service mapreduce_shuffle
2016-10-05 17:45:37,891 INFO org.apache.hadoop.mapred.ShuffleHandler: Added token for job_1475714661937_0001
2016-10-05 17:45:37,892 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000006
2016-10-05 17:45:37,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000009
2016-10-05 17:45:37,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000005
2016-10-05 17:45:37,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000007
2016-10-05 17:45:37,894 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000008
2016-10-05 17:45:37,895 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000002
2016-10-05 17:45:37,895 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000003
2016-10-05 17:45:37,895 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Created localizer for container_1475714661937_0001_01_000004
2016-10-05 17:45:37,997 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000005.tokens. Credentials list: 
2016-10-05 17:45:37,997 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000002.tokens. Credentials list: 
2016-10-05 17:45:37,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000009.tokens. Credentials list: 
2016-10-05 17:45:37,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000008.tokens. Credentials list: 
2016-10-05 17:45:37,998 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000007.tokens. Credentials list: 
2016-10-05 17:45:37,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000004.tokens. Credentials list: 
2016-10-05 17:45:37,999 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000006.tokens. Credentials list: 
2016-10-05 17:45:38,000 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Writing credentials to the nmPrivate file /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000003.tokens. Credentials list: 
2016-10-05 17:45:38,017 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,047 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,058 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,068 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000003.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000003.tokens
2016-10-05 17:45:38,068 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000002.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000002.tokens
2016-10-05 17:45:38,070 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000009.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000009.tokens
2016-10-05 17:45:38,070 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,070 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,070 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,074 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,076 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000007.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000007.tokens
2016-10-05 17:45:38,077 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,091 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,091 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,092 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,092 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Initializing user cloud
2016-10-05 17:45:38,094 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000004.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000004.tokens
2016-10-05 17:45:38,094 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,095 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000005.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000005.tokens
2016-10-05 17:45:38,095 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,095 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000008.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000008.tokens
2016-10-05 17:45:38,096 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,104 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Copying from /tmp/hadoop-cloud/nm-local-dir/nmPrivate/container_1475714661937_0001_01_000006.tokens to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000006.tokens
2016-10-05 17:45:38,105 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Localizer CWD set to /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001 = file:/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:38,755 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://master1:9000/tmp/hadoop-yarn/staging/cloud/.staging/job_1475714661937_0001/job.jar(->/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED
2016-10-05 17:45:38,759 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource: Resource hdfs://master1:9000/tmp/hadoop-yarn/staging/cloud/.staging/job_1475714661937_0001/job.xml(->/tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED
2016-10-05 17:45:38,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,761 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,761 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,761 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from LOCALIZING to LOCALIZED
2016-10-05 17:45:38,797 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,797 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,799 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,801 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,802 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,802 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000008/default_container_executor.sh]
2016-10-05 17:45:38,803 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000006/default_container_executor.sh]
2016-10-05 17:45:38,805 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000005/default_container_executor.sh]
2016-10-05 17:45:38,806 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000009/default_container_executor.sh]
2016-10-05 17:45:38,810 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,816 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000004/default_container_executor.sh]
2016-10-05 17:45:38,817 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000002/default_container_executor.sh]
2016-10-05 17:45:38,817 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from LOCALIZED to RUNNING
2016-10-05 17:45:38,820 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000007/default_container_executor.sh]
2016-10-05 17:45:38,822 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: launchContainer: [bash, /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000003/default_container_executor.sh]
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000009
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000006
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000005
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000007
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000008
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000002
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000003
2016-10-05 17:45:40,451 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Starting resource-monitoring for container_1475714661937_0001_01_000004
2016-10-05 17:45:40,588 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6059 for container-id container_1475714661937_0001_01_000006: 95.2 MB of 1 GB physical memory used; 774.0 MB of 2.1 GB virtual memory used
2016-10-05 17:45:40,769 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6058 for container-id container_1475714661937_0001_01_000009: 100.8 MB of 1 GB physical memory used; 773.1 MB of 2.1 GB virtual memory used
2016-10-05 17:45:40,856 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6053 for container-id container_1475714661937_0001_01_000005: 100.7 MB of 1 GB physical memory used; 774.7 MB of 2.1 GB virtual memory used
2016-10-05 17:45:40,923 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6087 for container-id container_1475714661937_0001_01_000007: 106.4 MB of 1 GB physical memory used; 766.5 MB of 2.1 GB virtual memory used
2016-10-05 17:45:40,979 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6051 for container-id container_1475714661937_0001_01_000008: 111.4 MB of 1 GB physical memory used; 767.7 MB of 2.1 GB virtual memory used
2016-10-05 17:45:41,027 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6078 for container-id container_1475714661937_0001_01_000002: 99.0 MB of 1 GB physical memory used; 766.5 MB of 2.1 GB virtual memory used
2016-10-05 17:45:41,071 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6099 for container-id container_1475714661937_0001_01_000003: 96.1 MB of 1 GB physical memory used; 775.3 MB of 2.1 GB virtual memory used
2016-10-05 17:45:41,118 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6075 for container-id container_1475714661937_0001_01_000004: 105.6 MB of 1 GB physical memory used; 773.6 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,141 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6059 for container-id container_1475714661937_0001_01_000006: 152.9 MB of 1 GB physical memory used; 806.0 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,162 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6058 for container-id container_1475714661937_0001_01_000009: 158.2 MB of 1 GB physical memory used; 808.0 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,183 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6053 for container-id container_1475714661937_0001_01_000005: 151.7 MB of 1 GB physical memory used; 806.6 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,205 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6087 for container-id container_1475714661937_0001_01_000007: 150.6 MB of 1 GB physical memory used; 796.5 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,227 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6051 for container-id container_1475714661937_0001_01_000008: 159.9 MB of 1 GB physical memory used; 795.3 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,248 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6078 for container-id container_1475714661937_0001_01_000002: 153.1 MB of 1 GB physical memory used; 795.3 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,268 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6099 for container-id container_1475714661937_0001_01_000003: 150.4 MB of 1 GB physical memory used; 806.9 MB of 2.1 GB virtual memory used
2016-10-05 17:45:44,291 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Memory usage of ProcessTree 6075 for container-id container_1475714661937_0001_01_000004: 147.6 MB of 1 GB physical memory used; 803.7 MB of 2.1 GB virtual memory used
2016-10-05 17:45:45,568 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,578 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000006
2016-10-05 17:45:45,578 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000006
2016-10-05 17:45:45,579 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,579 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000006
2016-10-05 17:45:45,642 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,658 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000006 is : 143
2016-10-05 17:45:45,679 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000007
2016-10-05 17:45:45,679 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000007
2016-10-05 17:45:45,697 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,697 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,699 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000006
2016-10-05 17:45:45,699 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000007
2016-10-05 17:45:45,731 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000007 is : 143
2016-10-05 17:45:45,737 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,740 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,746 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,752 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000002
2016-10-05 17:45:45,752 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000002
2016-10-05 17:45:45,755 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000009
2016-10-05 17:45:45,755 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000009
2016-10-05 17:45:45,760 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000005
2016-10-05 17:45:45,760 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000005
2016-10-05 17:45:45,766 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,771 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000004
2016-10-05 17:45:45,771 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000004
2016-10-05 17:45:45,777 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:45,779 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000008
2016-10-05 17:45:45,780 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000008
2016-10-05 17:45:45,783 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000006
2016-10-05 17:45:45,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000006 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,785 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from RUNNING to KILLING
2016-10-05 17:45:45,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000006 from application application_1475714661937_0001
2016-10-05 17:45:45,786 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,787 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000007
2016-10-05 17:45:45,787 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000002
2016-10-05 17:45:45,797 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000002 is : 143
2016-10-05 17:45:45,811 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000009
2016-10-05 17:45:45,821 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000009 is : 143
2016-10-05 17:45:45,839 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000005
2016-10-05 17:45:45,847 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000005 is : 143
2016-10-05 17:45:45,868 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000004
2016-10-05 17:45:45,878 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000004 is : 143
2016-10-05 17:45:45,897 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000008
2016-10-05 17:45:45,905 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000008 is : 143
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000007
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000007 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,927 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:45,928 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000007 from application application_1475714661937_0001
2016-10-05 17:45:45,928 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,928 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000002
2016-10-05 17:45:45,929 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000009
2016-10-05 17:45:45,930 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000005
2016-10-05 17:45:45,931 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000004
2016-10-05 17:45:45,931 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000008
2016-10-05 17:45:45,932 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000002
2016-10-05 17:45:45,932 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000002 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,932 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000009
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000009 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000005
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000005 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000004
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000004 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000008
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000008 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000002 from application application_1475714661937_0001
2016-10-05 17:45:45,933 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000009 from application application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000005 from application application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000004 from application application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000008 from application application_1475714661937_0001
2016-10-05 17:45:45,934 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:46,089 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1475714661937_0001_000001 (auth:SIMPLE)
2016-10-05 17:45:46,092 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Stopping container with container Id: container_1475714661937_0001_01_000003
2016-10-05 17:45:46,092 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	IP=199.60.17.228	OPERATION=Stop Container Request	TARGET=ContainerManageImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000003
2016-10-05 17:45:46,092 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from RUNNING to KILLING
2016-10-05 17:45:46,093 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch: Cleaning up container container_1475714661937_0001_01_000003
2016-10-05 17:45:46,103 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Exit code from container container_1475714661937_0001_01_000003 is : 143
2016-10-05 17:45:46,119 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL
2016-10-05 17:45:46,119 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001/container_1475714661937_0001_01_000003
2016-10-05 17:45:46,119 INFO org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger: USER=cloud	OPERATION=Container Finished - Killed	TARGET=ContainerImpl	RESULT=SUCCESS	APPID=application_1475714661937_0001	CONTAINERID=container_1475714661937_0001_01_000003
2016-10-05 17:45:46,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl: Container container_1475714661937_0001_01_000003 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE
2016-10-05 17:45:46,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Removing container_1475714661937_0001_01_000003 from application application_1475714661937_0001
2016-10-05 17:45:46,120 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event CONTAINER_STOP for appId application_1475714661937_0001
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000006
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000007
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000002
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000009
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000005
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000004
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000008
2016-10-05 17:45:47,292 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Stopping resource-monitoring for container_1475714661937_0001_01_000003
2016-10-05 17:45:48,105 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: [container_1475714661937_0001_01_000006, container_1475714661937_0001_01_000009, container_1475714661937_0001_01_000005, container_1475714661937_0001_01_000007, container_1475714661937_0001_01_000008, container_1475714661937_0001_01_000002, container_1475714661937_0001_01_000004]
2016-10-05 17:45:49,108 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Removed completed containers from NM context: [container_1475714661937_0001_01_000003]
2016-10-05 17:45:51,318 INFO org.apache.hadoop.mapred.ShuffleHandler: Setting connection close header...
2016-10-05 17:45:51,345 INFO org.apache.hadoop.mapred.ShuffleHandler: Setting connection close header...
2016-10-05 17:45:59,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application application_1475714661937_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP
2016-10-05 17:45:59,140 INFO org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor: Deleting absolute path : /tmp/hadoop-cloud/nm-local-dir/usercache/cloud/appcache/application_1475714661937_0001
2016-10-05 17:45:59,140 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Got event APPLICATION_STOP for appId application_1475714661937_0001
2016-10-05 17:45:59,141 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl: Application application_1475714661937_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED
2016-10-05 17:45:59,141 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler: Scheduling Log Deletion for application: application_1475714661937_0001, with delay of 10800 seconds
2016-10-05 17:59:21,243 ERROR org.apache.hadoop.yarn.server.nodemanager.NodeManager: RECEIVED SIGNAL 15: SIGTERM
2016-10-05 17:59:21,264 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8042
2016-10-05 17:59:21,264 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Applications still running : [application_1475714661937_0001]
2016-10-05 17:59:21,264 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Waiting for Applications to be Finished
2016-10-05 17:59:25,265 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Done waiting for Applications to be Finished. Still alive: [application_1475714661937_0001]
2016-10-05 17:59:25,266 INFO org.apache.hadoop.ipc.Server: Stopping server on 38523
2016-10-05 17:59:25,267 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 38523
2016-10-05 17:59:25,268 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
