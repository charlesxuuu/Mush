2016-10-04 20:56:32,315 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master1/199.60.17.185
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.0
STARTUP_MSG:   classpath = /home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-auth-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf; compiled by 'jenkins' on 2015-04-10T18:40Z
STARTUP_MSG:   java = 1.7.0_111
************************************************************/
2016-10-04 20:56:32,324 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-10-04 20:56:32,329 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-10-04 20:56:32,671 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-10-04 20:56:32,794 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-10-04 20:56:32,794 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-10-04 20:56:32,797 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://199.60.17.185:9000
2016-10-04 20:56:32,797 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use 199.60.17.185:9000 to access this namenode/service.
2016-10-04 20:56:33,103 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-10-04 20:56:33,156 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-10-04 20:56:33,165 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-10-04 20:56:33,171 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-10-04 20:56:33,176 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-10-04 20:56:33,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-10-04 20:56:33,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-10-04 20:56:33,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-10-04 20:56:33,204 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-10-04 20:56:33,205 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-10-04 20:56:33,221 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-10-04 20:56:33,221 INFO org.mortbay.log: jetty-6.1.26
2016-10-04 20:56:33,446 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-10-04 20:56:33,476 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-10-04 20:56:33,476 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-10-04 20:56:33,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-10-04 20:56:33,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-10-04 20:56:33,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-10-04 20:56:33,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-10-04 20:56:33,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-10-04 20:56:33,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Oct 04 20:56:33
2016-10-04 20:56:33,559 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-10-04 20:56:33,560 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-10-04 20:56:33,561 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2016-10-04 20:56:33,561 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-10-04 20:56:33,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-10-04 20:56:33,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-10-04 20:56:33,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-10-04 20:56:33,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-10-04 20:56:33,590 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-10-04 20:56:33,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2016-10-04 20:56:33,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-10-04 20:56:33,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-10-04 20:56:33,591 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-10-04 20:56:33,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = cloud (auth:SIMPLE)
2016-10-04 20:56:33,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-10-04 20:56:33,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-10-04 20:56:33,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-10-04 20:56:33,600 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-10-04 20:56:33,640 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-10-04 20:56:33,640 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-10-04 20:56:33,640 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2016-10-04 20:56:33,640 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-10-04 20:56:33,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-10-04 20:56:33,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-10-04 20:56:33,641 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-10-04 20:56:33,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-10-04 20:56:33,648 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-10-04 20:56:33,648 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-10-04 20:56:33,648 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2016-10-04 20:56:33,648 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-10-04 20:56:33,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-10-04 20:56:33,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-10-04 20:56:33,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-10-04 20:56:33,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-10-04 20:56:33,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-10-04 20:56:33,652 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-10-04 20:56:33,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-10-04 20:56:33,653 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-10-04 20:56:33,655 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-10-04 20:56:33,655 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-10-04 20:56:33,655 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2016-10-04 20:56:33,656 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-10-04 20:56:33,676 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-cloud/dfs/name/in_use.lock acquired by nodename 73565@master1
2016-10-04 20:56:33,759 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-cloud/dfs/name/current
2016-10-04 20:56:33,760 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-10-04 20:56:33,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-10-04 20:56:33,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-10-04 20:56:33,827 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-cloud/dfs/name/current/fsimage_0000000000000000000
2016-10-04 20:56:33,836 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-10-04 20:56:33,836 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-10-04 20:56:33,890 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-10-04 20:56:33,890 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 231 msecs
2016-10-04 20:56:34,049 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master1:9000
2016-10-04 20:56:34,055 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-10-04 20:56:34,066 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2016-10-04 20:56:34,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-10-04 20:56:34,158 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-10-04 20:56:34,158 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-10-04 20:56:34,158 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-10-04 20:56:34,159 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-10-04 20:56:34,159 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-10-04 20:56:34,159 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-10-04 20:56:34,165 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-10-04 20:56:34,166 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2016-10-04 20:56:34,196 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-10-04 20:56:34,197 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2016-10-04 20:56:34,199 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master1/199.60.17.185:9000
2016-10-04 20:56:34,199 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-10-04 20:56:34,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-10-04 20:56:38,510 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.185:50010, datanodeUuid=828ef62a-51af-42e0-a23b-8a3425c7be79, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d114ce2e-eaed-4077-ae12-f47343ade6f5;nsid=297584293;c=0) storage 828ef62a-51af-42e0-a23b-8a3425c7be79
2016-10-04 20:56:38,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-10-04 20:56:38,511 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.185:50010
2016-10-04 20:56:38,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-10-04 20:56:38,583 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-78cac6aa-4974-43b9-b290-b15daa326dd6 for DN 199.60.17.185:50010
2016-10-04 20:56:38,623 INFO BlockStateChange: BLOCK* processReport: from storage DS-78cac6aa-4974-43b9-b290-b15daa326dd6 node DatanodeRegistration(199.60.17.185:50010, datanodeUuid=828ef62a-51af-42e0-a23b-8a3425c7be79, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-d114ce2e-eaed-4077-ae12-f47343ade6f5;nsid=297584293;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-10-04 20:57:50,286 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 199.60.17.185
2016-10-04 20:57:50,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-10-04 20:57:50,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-10-04 20:57:50,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-10-04 20:57:50,287 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 10 
2016-10-04 20:57:50,289 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-cloud/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-cloud/dfs/name/current/edits_0000000000000000001-0000000000000000002
2016-10-04 20:57:50,292 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2016-10-04 20:57:51,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-10-04 20:57:51,476 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 352 bytes.
2016-10-04 20:57:51,481 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2016-10-04 20:57:57,167 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 20:58:03,323 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 20:58:04,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 20:58:07,462 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 20:58:07,995 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 20:59:06,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 6 
2016-10-04 21:03:43,149 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 
2016-10-04 21:04:58,968 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 4 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 8 
2016-10-04 21:04:59,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/capacity-scheduler.xml._COPYING_
2016-10-04 21:04:59,288 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/cloud/input/capacity-scheduler.xml._COPYING_
2016-10-04 21:04:59,288 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2016-10-04 21:04:59,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 4436
2016-10-04 21:04:59,696 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,721 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/configuration.xsl._COPYING_
2016-10-04 21:04:59,729 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/configuration.xsl._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/container-executor.cfg._COPYING_
2016-10-04 21:04:59,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,751 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/container-executor.cfg._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,761 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/core-site.xml._COPYING_
2016-10-04 21:04:59,768 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,781 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hadoop-env.cmd._COPYING_
2016-10-04 21:04:59,787 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hadoop-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hadoop-env.sh._COPYING_
2016-10-04 21:04:59,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hadoop-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hadoop-metrics.properties._COPYING_
2016-10-04 21:04:59,825 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,827 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hadoop-metrics.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hadoop-metrics2.properties._COPYING_
2016-10-04 21:04:59,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,845 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hadoop-metrics2.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hadoop-policy.xml._COPYING_
2016-10-04 21:04:59,861 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,863 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/hdfs-site.xml._COPYING_
2016-10-04 21:04:59,881 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,883 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/httpfs-env.sh._COPYING_
2016-10-04 21:04:59,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/httpfs-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/httpfs-log4j.properties._COPYING_
2016-10-04 21:04:59,917 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,923 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/httpfs-log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/httpfs-signature.secret._COPYING_
2016-10-04 21:04:59,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,943 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/httpfs-signature.secret._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/httpfs-site.xml._COPYING_
2016-10-04 21:04:59,962 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,974 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/kms-acls.xml._COPYING_
2016-10-04 21:04:59,980 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:04:59,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:04:59,994 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/kms-env.sh._COPYING_
2016-10-04 21:05:00,000 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,002 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/kms-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/kms-log4j.properties._COPYING_
2016-10-04 21:05:00,018 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,020 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/kms-log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,031 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/kms-site.xml._COPYING_
2016-10-04 21:05:00,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,038 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,048 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/log4j.properties._COPYING_
2016-10-04 21:05:00,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,055 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/log4j.properties._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,066 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/mapred-env.cmd._COPYING_
2016-10-04 21:05:00,071 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741844_1020{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,073 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/mapred-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/mapred-env.sh._COPYING_
2016-10-04 21:05:00,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741845_1021{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,090 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/mapred-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,100 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/mapred-queues.xml.template._COPYING_
2016-10-04 21:05:00,105 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741846_1022{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,106 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/mapred-queues.xml.template._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/mapred-site.xml.template._COPYING_
2016-10-04 21:05:00,122 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741847_1023{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/mapred-site.xml.template._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,134 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/slaves._COPYING_
2016-10-04 21:05:00,139 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741848_1024{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/slaves._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,151 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/ssl-client.xml.example._COPYING_
2016-10-04 21:05:00,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741849_1025{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,158 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/ssl-client.xml.example._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,170 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/ssl-server.xml.example._COPYING_
2016-10-04 21:05:00,176 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741850_1026{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,177 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/ssl-server.xml.example._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,187 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/yarn-env.cmd._COPYING_
2016-10-04 21:05:00,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741851_1027{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/yarn-env.cmd._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/yarn-env.sh._COPYING_
2016-10-04 21:05:00,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741852_1028{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,211 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/yarn-env.sh._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:00,222 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/input/yarn-site.xml._COPYING_
2016-10-04 21:05:00,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741853_1029{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:00,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/input/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_34280036_1
2016-10-04 21:05:20,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/grep-temp-487962939/_temporary/0/_temporary/attempt_local821903850_0001_r_000000_0/part-r-00000
2016-10-04 21:05:20,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741854_1030{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:20,903 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/grep-temp-487962939/_temporary/0/_temporary/attempt_local821903850_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-1889926174_1
2016-10-04 21:05:20,957 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/grep-temp-487962939/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1889926174_1
2016-10-04 21:05:21,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} for /user/cloud/output/_temporary/0/_temporary/attempt_local329830845_0002_r_000000_0/part-r-00000
2016-10-04 21:05:21,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.185:50010 is added to blk_1073741855_1031{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-78cac6aa-4974-43b9-b290-b15daa326dd6:NORMAL:199.60.17.185:50010|RBW]]} size 0
2016-10-04 21:05:21,556 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/output/_temporary/0/_temporary/attempt_local329830845_0002_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_-1889926174_1
2016-10-04 21:05:21,580 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/cloud/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1889926174_1
2016-10-04 21:05:22,507 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 199.60.17.185:50010 
2016-10-04 21:05:25,209 INFO BlockStateChange: BLOCK* BlockManager: ask 199.60.17.185:50010 to delete [blk_1073741854_1030]
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-10-04 21:13:28,996 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 1
2016-10-04 21:13:28,997 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-10-04 21:13:28,998 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-10-04 21:13:29,005 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-10-04 21:14:38,220 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-10-04 21:14:38,222 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master1/199.60.17.185
************************************************************/
2016-12-26 16:47:49,179 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master1/199.60.17.228
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.0
STARTUP_MSG:   classpath = /home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-auth-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf; compiled by 'jenkins' on 2015-04-10T18:40Z
STARTUP_MSG:   java = 1.7.0_121
************************************************************/
2016-12-26 16:47:49,185 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-12-26 16:47:49,189 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-12-26 16:47:49,477 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-12-26 16:47:49,558 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-26 16:47:49,558 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-12-26 16:47:49,560 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://master1:9000
2016-12-26 16:47:49,561 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use master1:9000 to access this namenode/service.
2016-12-26 16:47:49,788 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-12-26 16:47:49,836 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-26 16:47:49,844 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-26 16:47:49,849 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-12-26 16:47:49,855 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-26 16:47:49,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-12-26 16:47:49,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-12-26 16:47:49,858 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-26 16:47:49,880 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-12-26 16:47:49,881 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-12-26 16:47:49,895 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-12-26 16:47:49,896 INFO org.mortbay.log: jetty-6.1.26
2016-12-26 16:47:50,032 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-12-26 16:47:50,057 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-12-26 16:47:50,057 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-12-26 16:47:50,089 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-12-26 16:47:50,089 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-12-26 16:47:50,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-12-26 16:47:50,126 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-12-26 16:47:50,127 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-12-26 16:47:50,128 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Dec 26 16:47:50
2016-12-26 16:47:50,129 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-12-26 16:47:50,130 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:47:50,131 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2016-12-26 16:47:50,131 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-12-26 16:47:50,161 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-12-26 16:47:50,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-12-26 16:47:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = cloud (auth:SIMPLE)
2016-12-26 16:47:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-12-26 16:47:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-12-26 16:47:50,168 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-12-26 16:47:50,169 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-12-26 16:47:50,201 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-12-26 16:47:50,201 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:47:50,201 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2016-12-26 16:47:50,201 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-12-26 16:47:50,202 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-12-26 16:47:50,202 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-12-26 16:47:50,202 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-12-26 16:47:50,202 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-12-26 16:47:50,207 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-12-26 16:47:50,207 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:47:50,207 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2016-12-26 16:47:50,207 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-12-26 16:47:50,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-12-26 16:47:50,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-12-26 16:47:50,208 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-12-26 16:47:50,210 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-12-26 16:47:50,210 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-12-26 16:47:50,210 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-12-26 16:47:50,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-12-26 16:47:50,212 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-12-26 16:47:50,213 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-12-26 16:47:50,213 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:47:50,213 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2016-12-26 16:47:50,213 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-12-26 16:47:50,223 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/cloud/hadoop/dfs/name/in_use.lock acquired by nodename 13162@master1
2016-12-26 16:47:50,278 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/cloud/hadoop/dfs/name/current
2016-12-26 16:47:50,278 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2016-12-26 16:47:50,311 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-12-26 16:47:50,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-12-26 16:47:50,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/cloud/hadoop/dfs/name/current/fsimage_0000000000000000000
2016-12-26 16:47:50,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-12-26 16:47:50,343 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2016-12-26 16:47:50,391 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-12-26 16:47:50,391 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 175 msecs
2016-12-26 16:47:50,521 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master1:9000
2016-12-26 16:47:50,527 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-12-26 16:47:50,535 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2016-12-26 16:47:50,602 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-12-26 16:47:50,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-12-26 16:47:50,613 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-12-26 16:47:50,614 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2016-12-26 16:47:50,638 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-12-26 16:47:50,638 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2016-12-26 16:47:50,640 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master1/199.60.17.228:9000
2016-12-26 16:47:50,640 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-12-26 16:47:50,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-12-26 16:47:55,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 16:47:55,495 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:47:55,496 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 16:47:55,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:47:55,558 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 for DN 199.60.17.222:50010
2016-12-26 16:47:55,591 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 16:47:55,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.226:50010, datanodeUuid=5b93b698-9ea1-4491-952f-2c614cb83915, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage 5b93b698-9ea1-4491-952f-2c614cb83915
2016-12-26 16:47:55,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:47:55,775 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.226:50010
2016-12-26 16:47:55,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:47:55,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-89f396de-be09-422a-bcc4-e471324d565c for DN 199.60.17.226:50010
2016-12-26 16:47:55,828 INFO BlockStateChange: BLOCK* processReport: from storage DS-89f396de-be09-422a-bcc4-e471324d565c node DatanodeRegistration(199.60.17.226:50010, datanodeUuid=5b93b698-9ea1-4491-952f-2c614cb83915, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 16:49:02,979 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 199.60.17.228
2016-12-26 16:49:02,979 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-12-26 16:49:02,979 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2016-12-26 16:49:02,979 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7 
2016-12-26 16:49:02,980 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 8 
2016-12-26 16:49:02,981 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/cloud/hadoop/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/cloud/hadoop/dfs/name/current/edits_0000000000000000001-0000000000000000002
2016-12-26 16:49:02,982 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2016-12-26 16:49:03,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-12-26 16:49:03,767 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 352 bytes.
2016-12-26 16:49:03,771 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2016-12-26 16:50:40,511 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 16:57:26,698 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2016-12-26 16:57:26,699 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master1/199.60.17.228
************************************************************/
2016-12-26 16:58:01,536 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master1/199.60.17.228
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.0
STARTUP_MSG:   classpath = /home/cloud/hadoop-2.7.0/etc/hadoop:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-auth-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/common/hadoop-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/hdfs/hadoop-hdfs-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-client-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-registry-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-api-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/yarn/hadoop-yarn-server-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.0.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.0-tests.jar:/home/cloud/hadoop-2.7.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r d4c8d4d4d203c934e8074b31289a28724c0842cf; compiled by 'jenkins' on 2015-04-10T18:40Z
STARTUP_MSG:   java = 1.7.0_121
************************************************************/
2016-12-26 16:58:01,543 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2016-12-26 16:58:01,546 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2016-12-26 16:58:01,830 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-12-26 16:58:01,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-26 16:58:01,910 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2016-12-26 16:58:01,912 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://master1:9000
2016-12-26 16:58:01,912 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use master1:9000 to access this namenode/service.
2016-12-26 16:58:02,135 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2016-12-26 16:58:02,183 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-26 16:58:02,191 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2016-12-26 16:58:02,196 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2016-12-26 16:58:02,201 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2016-12-26 16:58:02,205 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2016-12-26 16:58:02,205 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-26 16:58:02,205 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2016-12-26 16:58:02,226 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2016-12-26 16:58:02,228 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2016-12-26 16:58:02,242 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2016-12-26 16:58:02,242 INFO org.mortbay.log: jetty-6.1.26
2016-12-26 16:58:02,378 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2016-12-26 16:58:02,403 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-12-26 16:58:02,403 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2016-12-26 16:58:02,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: No KeyProvider found.
2016-12-26 16:58:02,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2016-12-26 16:58:02,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2016-12-26 16:58:02,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2016-12-26 16:58:02,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2016-12-26 16:58:02,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2016 Dec 26 16:58:02
2016-12-26 16:58:02,477 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2016-12-26 16:58:02,477 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:58:02,478 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2016-12-26 16:58:02,479 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2016-12-26 16:58:02,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2016-12-26 16:58:02,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = cloud (auth:SIMPLE)
2016-12-26 16:58:02,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2016-12-26 16:58:02,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2016-12-26 16:58:02,522 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2016-12-26 16:58:02,523 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2016-12-26 16:58:02,558 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2016-12-26 16:58:02,558 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:58:02,559 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2016-12-26 16:58:02,559 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2016-12-26 16:58:02,559 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2016-12-26 16:58:02,559 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2016-12-26 16:58:02,559 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Maximum size of an xattr: 16384
2016-12-26 16:58:02,559 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2016-12-26 16:58:02,565 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2016-12-26 16:58:02,565 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:58:02,565 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2016-12-26 16:58:02,565 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2016-12-26 16:58:02,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2016-12-26 16:58:02,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2016-12-26 16:58:02,566 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2016-12-26 16:58:02,569 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2016-12-26 16:58:02,569 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2016-12-26 16:58:02,569 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2016-12-26 16:58:02,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2016-12-26 16:58:02,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2016-12-26 16:58:02,572 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2016-12-26 16:58:02,572 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2016-12-26 16:58:02,572 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2016-12-26 16:58:02,572 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2016-12-26 16:58:02,582 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/cloud/hadoop/dfs/name/in_use.lock acquired by nodename 15315@master1
2016-12-26 16:58:02,640 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/cloud/hadoop/dfs/name/current
2016-12-26 16:58:02,690 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/cloud/hadoop/dfs/name/current/edits_inprogress_0000000000000000003 -> /home/cloud/hadoop/dfs/name/current/edits_0000000000000000003-0000000000000000003
2016-12-26 16:58:02,727 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2016-12-26 16:58:02,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2016-12-26 16:58:02,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /home/cloud/hadoop/dfs/name/current/fsimage_0000000000000000002
2016-12-26 16:58:02,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36d41a34 expecting start txid #3
2016-12-26 16:58:02,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /home/cloud/hadoop/dfs/name/current/edits_0000000000000000003-0000000000000000003
2016-12-26 16:58:02,754 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/home/cloud/hadoop/dfs/name/current/edits_0000000000000000003-0000000000000000003' to transaction ID 3
2016-12-26 16:58:02,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /home/cloud/hadoop/dfs/name/current/edits_0000000000000000003-0000000000000000003 of size 1048576 edits # 1 loaded in 0 seconds
2016-12-26 16:58:02,760 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2016-12-26 16:58:02,760 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 4
2016-12-26 16:58:02,800 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2016-12-26 16:58:02,800 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 225 msecs
2016-12-26 16:58:02,927 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master1:9000
2016-12-26 16:58:02,932 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2016-12-26 16:58:02,940 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2016-12-26 16:58:02,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2016-12-26 16:58:02,989 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-12-26 16:58:02,989 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2016-12-26 16:58:02,989 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2016-12-26 16:58:02,990 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2016-12-26 16:58:02,990 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2016-12-26 16:58:02,990 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2016-12-26 16:58:02,995 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2016-12-26 16:58:02,996 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2016-12-26 16:58:03,020 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-12-26 16:58:03,020 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2016-12-26 16:58:03,022 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master1/199.60.17.228:9000
2016-12-26 16:58:03,022 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2016-12-26 16:58:03,025 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2016-12-26 16:58:07,463 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 16:58:07,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:07,464 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 16:58:07,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:07,528 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 for DN 199.60.17.222:50010
2016-12-26 16:58:07,562 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 16:58:07,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.226:50010, datanodeUuid=5b93b698-9ea1-4491-952f-2c614cb83915, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage 5b93b698-9ea1-4491-952f-2c614cb83915
2016-12-26 16:58:07,730 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:07,730 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.226:50010
2016-12-26 16:58:07,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:07,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-89f396de-be09-422a-bcc4-e471324d565c for DN 199.60.17.226:50010
2016-12-26 16:58:07,785 INFO BlockStateChange: BLOCK* processReport: from storage DS-89f396de-be09-422a-bcc4-e471324d565c node DatanodeRegistration(199.60.17.226:50010, datanodeUuid=5b93b698-9ea1-4491-952f-2c614cb83915, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 16:58:08,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.227:50010, datanodeUuid=5cd60314-1f3a-47e1-81da-f01518d998ed, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage 5cd60314-1f3a-47e1-81da-f01518d998ed
2016-12-26 16:58:08,251 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:08,251 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.227:50010
2016-12-26 16:58:08,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 16:58:08,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf for DN 199.60.17.227:50010
2016-12-26 16:58:08,330 INFO BlockStateChange: BLOCK* processReport: from storage DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf node DatanodeRegistration(199.60.17.227:50010, datanodeUuid=5cd60314-1f3a-47e1-81da-f01518d998ed, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 16:59:07,223 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-12-26 16:59:12,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 199.60.17.228
2016-12-26 16:59:12,142 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-12-26 16:59:12,142 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 4
2016-12-26 16:59:12,143 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 11 
2016-12-26 16:59:12,144 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/cloud/hadoop/dfs/name/current/edits_inprogress_0000000000000000004 -> /home/cloud/hadoop/dfs/name/current/edits_0000000000000000004-0000000000000000006
2016-12-26 16:59:12,144 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 7
2016-12-26 16:59:12,856 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2016-12-26 16:59:12,856 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000006 size 428 bytes.
2016-12-26 16:59:12,860 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2016-12-26 16:59:12,860 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/cloud/hadoop/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2016-12-26 17:02:23,122 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 9 
2016-12-26 17:02:23,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} for /test/test.txt._COPYING_
2016-12-26 17:02:23,525 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /test/test.txt._COPYING_
2016-12-26 17:02:23,533 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 29
2016-12-26 17:02:23,533 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741825_1001 size 29
2016-12-26 17:02:23,534 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741825_1001 size 29
2016-12-26 17:02:23,932 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test/test.txt._COPYING_ is closed by DFSClient_NONMAPREDUCE_1540113781_1
2016-12-26 17:02:39,915 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by cloud (auth:SIMPLE) from /199.60.17.228 for path / at Mon Dec 26 17:02:39 PST 2016
2016-12-26 17:04:10,957 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 12 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 6 SyncTimes(ms): 11 
2016-12-26 17:04:11,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.jar
2016-12-26 17:04:11,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,193 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.jar is closed by DFSClient_NONMAPREDUCE_584545012_1
2016-12-26 17:04:11,196 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741826_1002 size 273436
2016-12-26 17:04:11,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.jar
2016-12-26 17:04:11,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.split
2016-12-26 17:04:11,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.split
2016-12-26 17:04:11,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.split is closed by DFSClient_NONMAPREDUCE_584545012_1
2016-12-26 17:04:11,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.splitmetainfo
2016-12-26 17:04:11,292 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,296 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_584545012_1
2016-12-26 17:04:11,468 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.xml
2016-12-26 17:04:11,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,488 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:11,491 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job.xml is closed by DFSClient_NONMAPREDUCE_584545012_1
2016-12-26 17:04:16,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job_1482800297511_0001_1_conf.xml
2016-12-26 17:04:16,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:16,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:16,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:16,677 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job_1482800297511_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:22,069 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job_1482800297511_0001_1.jhist
2016-12-26 17:04:22,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job_1482800297511_0001_1.jhist for DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,570 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} for /testoutput/_temporary/1/_temporary/attempt_1482800297511_0001_r_000000_0/part-r-00000
2016-12-26 17:04:27,675 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,679 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,682 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testoutput/_temporary/1/_temporary/attempt_1482800297511_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1482800297511_0001_r_000000_0_1762992480_1
2016-12-26 17:04:27,801 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /testoutput/_SUCCESS is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 13050
2016-12-26 17:04:27,860 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 13050
2016-12-26 17:04:27,861 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 13050
2016-12-26 17:04:27,864 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/cloud/.staging/job_1482800297511_0001/job_1482800297511_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001.summary_tmp
2016-12-26 17:04:27,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,888 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001-1482800651661-cloud-word+count-1482800667840-1-1-SUCCEEDED-default-1482800656305.jhist_tmp
2016-12-26 17:04:27,924 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,925 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW]]} size 0
2016-12-26 17:04:27,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001-1482800651661-cloud-word+count-1482800667840-1-1-SUCCEEDED-default-1482800656305.jhist_tmp is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:27,948 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} for /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001_conf.xml_tmp
2016-12-26 17:04:27,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.227:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.222:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 199.60.17.226:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-89f396de-be09-422a-bcc4-e471324d565c:NORMAL:199.60.17.226:50010|RBW], ReplicaUC[[DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.222:50010|RBW], ReplicaUC[[DISK]DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf:NORMAL:199.60.17.227:50010|RBW]]} size 0
2016-12-26 17:04:27,969 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/cloud/job_1482800297511_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_546166972_1
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 199.60.17.226:50010 199.60.17.222:50010 199.60.17.227:50010 
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 199.60.17.227:50010 199.60.17.226:50010 199.60.17.222:50010 
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 199.60.17.227:50010 199.60.17.226:50010 199.60.17.222:50010 
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 199.60.17.227:50010 199.60.17.226:50010 199.60.17.222:50010 
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 199.60.17.226:50010 199.60.17.227:50010 199.60.17.222:50010 
2016-12-26 17:04:28,999 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 199.60.17.226:50010 199.60.17.227:50010 199.60.17.222:50010 
2016-12-26 17:04:30,023 INFO BlockStateChange: BLOCK* BlockManager: ask 199.60.17.226:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007]
2016-12-26 17:04:33,023 INFO BlockStateChange: BLOCK* BlockManager: ask 199.60.17.222:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007]
2016-12-26 17:04:36,023 INFO BlockStateChange: BLOCK* BlockManager: ask 199.60.17.227:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007]
2016-12-26 17:43:03,058 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* removeDeadDatanode: lost heartbeat from 199.60.17.222:50010
2016-12-26 17:43:03,060 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:48:54,976 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 17:48:54,977 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 17:48:54,978 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 17:49:28,012 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:49:44,607 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:50:28,919 INFO BlockStateChange: BLOCK* processReport: from storage DS-89f396de-be09-422a-bcc4-e471324d565c node DatanodeRegistration(199.60.17.226:50010, datanodeUuid=5b93b698-9ea1-4491-952f-2c614cb83915, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:51:50,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:51:50,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:51:50,973 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:51:50,973 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:51:50,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:51:50,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: [DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:NORMAL:199.60.17.221:50010 failed.
2016-12-26 17:51:50,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Removed storage [DISK]DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70:FAILED:199.60.17.221:50010 from DataNode199.60.17.221:50010
2016-12-26 17:51:51,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:51:51,022 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 for DN 199.60.17.221:50010
2016-12-26 17:51:51,049 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:55:54,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:56:40,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:40,704 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:40,704 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:40,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:40,777 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:41,860 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:41,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:41,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:41,864 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:41,864 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:41,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:41,869 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:43,710 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:43,713 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:43,713 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:43,713 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:43,715 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:43,717 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:44,865 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:44,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:44,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:44,868 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:44,868 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:44,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:44,871 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:46,719 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:46,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:46,722 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:46,722 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:46,723 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:46,725 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:56:47,869 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:47,872 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:47,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:47,873 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:47,873 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:47,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:47,876 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:49,724 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:49,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:49,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:49,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:49,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:49,731 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:50,873 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:50,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:50,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:50,876 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:50,876 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:50,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:50,879 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:52,730 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:52,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:52,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:52,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:52,734 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:52,736 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:53,877 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:53,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:53,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:53,880 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:53,880 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:53,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:53,883 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:55,735 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:55,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:55,738 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:55,738 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:55,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:55,741 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:56,882 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:56,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:56,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:56,885 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:56,885 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:56,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:56,888 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:58,740 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:56:58,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:58,743 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:58,743 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:58,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:58,746 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:59,885 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:56:59,889 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:59,889 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:56:59,889 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:56:59,889 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:56:59,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:56:59,892 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:56:59,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:01,454 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:01,745 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:01,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:01,748 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:01,748 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:01,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:01,751 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:02,248 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:02,890 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:02,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:02,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:02,893 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:02,893 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:02,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:02,896 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:03,542 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:04,321 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:04,750 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:04,753 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:04,753 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:04,753 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:04,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:04,756 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:05,249 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:05,894 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:05,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:05,897 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:05,897 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:05,897 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:05,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:05,900 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:06,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:06,787 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:07,629 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:57:07,755 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:07,758 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:07,758 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:07,758 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:07,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:07,761 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:08,897 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:08,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:08,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:08,901 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:08,901 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:08,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:08,905 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:10,760 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:10,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:10,764 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:10,764 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:10,765 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:10,767 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:57:11,902 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:11,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:11,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:11,907 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:11,907 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:11,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:11,910 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:13,766 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:13,769 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:13,769 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:13,769 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:13,771 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:13,772 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:57:14,908 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:14,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:14,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:14,911 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:14,911 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:14,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:14,914 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:16,772 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:16,775 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:16,775 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:16,775 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:16,776 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:16,778 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:17,911 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:17,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:17,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:17,915 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:17,915 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:17,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:17,918 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:19,777 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:19,780 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:19,780 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:19,780 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:19,781 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:19,782 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:20,915 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:20,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:20,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:20,918 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:20,919 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:20,920 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:20,922 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:22,781 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:22,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:22,784 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:22,784 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:22,786 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:22,787 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:57:23,919 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:23,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:23,922 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:23,922 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:23,922 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:23,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:23,925 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:25,786 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:25,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:25,789 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:25,789 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:25,791 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:25,792 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:26,924 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:26,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:26,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:26,927 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:26,927 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:26,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:26,929 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:28,791 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:28,794 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:28,794 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:28,794 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:28,796 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:28,797 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:29,928 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:29,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:29,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:29,931 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:29,931 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:29,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:29,934 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:31,796 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:31,799 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:31,799 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:31,799 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:31,800 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:31,802 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:32,932 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:32,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:32,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:32,935 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:32,935 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:32,937 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:32,938 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:34,800 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:34,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:34,803 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:34,803 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:34,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:34,807 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:35,936 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:35,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:35,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:35,939 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:35,939 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:35,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:35,941 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:37,806 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:37,809 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:37,809 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:37,809 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:37,810 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:37,812 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:38,939 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:38,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:38,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:38,942 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:38,942 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:38,943 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:38,945 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:40,811 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:40,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:40,814 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:40,814 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:40,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:40,817 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:41,942 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:41,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:41,945 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:41,945 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:41,945 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:41,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:41,948 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:43,816 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:43,819 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:43,819 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:43,819 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:43,821 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:43,822 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:44,947 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:44,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:44,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:44,950 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:44,950 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:44,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:44,953 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:46,821 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:46,824 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:46,824 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:46,824 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:46,826 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:46,827 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:47,950 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:47,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:47,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:47,954 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:47,954 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:47,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:47,957 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:57:49,827 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:49,830 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:49,830 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:49,830 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:49,831 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:49,833 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:50,955 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:50,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:50,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:50,958 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:50,958 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:50,959 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:50,961 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:52,832 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:52,835 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:52,835 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:52,835 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:52,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:52,838 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:57:53,959 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:53,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:53,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:53,962 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:53,962 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:53,964 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:53,966 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:55,837 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:55,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:55,840 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:55,840 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:55,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:55,843 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:56,963 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:56,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:56,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:56,966 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:56,967 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:56,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:56,969 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:58,844 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:57:58,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:58,846 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:58,846 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:58,848 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:58,849 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:57:59,967 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:57:59,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:59,970 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:57:59,970 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:57:59,970 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:57:59,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:57:59,974 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:01,849 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:01,852 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:01,852 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:01,852 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:01,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:01,855 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:58:02,971 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:02,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:02,975 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:02,975 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:02,975 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:02,976 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:02,978 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:04,854 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:04,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:04,857 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:04,857 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:04,859 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:04,860 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:58:05,975 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:05,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:05,978 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:05,978 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:05,979 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:05,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:05,982 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:07,859 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:07,862 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:07,862 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:07,862 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:07,864 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:07,865 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:08,979 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:08,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:08,982 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:08,982 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:08,982 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:08,984 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:08,985 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:10,865 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:10,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:10,869 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:10,869 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:10,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:10,871 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 1 msecs
2016-12-26 17:58:11,983 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:11,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:11,986 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:11,986 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:11,986 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:11,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:11,989 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:13,871 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:13,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:13,874 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:13,874 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:13,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:13,878 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:14,987 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:14,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:14,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:14,990 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:14,990 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:14,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:14,993 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:16,876 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:16,879 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:16,879 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:16,879 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:16,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:16,882 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:17,991 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:17,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:17,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:17,995 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:17,995 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:17,997 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:17,998 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:19,881 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:19,884 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:19,884 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:19,884 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:19,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:19,888 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:20,996 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:20,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:20,999 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:20,999 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:20,999 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:21,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:21,005 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:22,886 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:22,889 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:22,889 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:22,889 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:22,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:22,892 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:24,000 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.222:50010 is expected to serve this storage.
2016-12-26 17:58:24,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:24,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 199.60.17.222:50010 is replaced by DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) with the same storageID a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:24,004 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:24,004 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:24,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:24,007 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:58:25,892 ERROR org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) is attempting to report storage ID a365ca87-9f3c-49ac-9a3a-951b5bda5b03. Node 199.60.17.221:50010 is expected to serve this storage.
2016-12-26 17:58:25,894 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage a365ca87-9f3c-49ac-9a3a-951b5bda5b03
2016-12-26 17:58:25,894 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/199.60.17.221:50010
2016-12-26 17:58:25,895 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.222:50010
2016-12-26 17:58:25,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:58:25,897 INFO BlockStateChange: BLOCK* processReport: from storage DS-2c78d1b2-57e9-4356-a61a-df10fa63fa70 node DatanodeRegistration(199.60.17.222:50010, datanodeUuid=a365ca87-9f3c-49ac-9a3a-951b5bda5b03, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:59:05,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 17:59:12,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(199.60.17.221:50010, datanodeUuid=b15d2a4e-a4e7-4aa8-97aa-4f4c69e7d72e, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0) storage b15d2a4e-a4e7-4aa8-97aa-4f4c69e7d72e
2016-12-26 17:59:12,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:59:12,645 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/199.60.17.221:50010
2016-12-26 17:59:12,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
2016-12-26 17:59:12,677 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-d814fe30-9e24-4121-994a-5f72b59e0f50 for DN 199.60.17.221:50010
2016-12-26 17:59:12,695 INFO BlockStateChange: BLOCK* processReport: from storage DS-d814fe30-9e24-4121-994a-5f72b59e0f50 node DatanodeRegistration(199.60.17.221:50010, datanodeUuid=b15d2a4e-a4e7-4aa8-97aa-4f4c69e7d72e, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2016-12-26 17:59:13,112 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 199.60.17.228
2016-12-26 17:59:13,112 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2016-12-26 17:59:13,112 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 7
2016-12-26 17:59:13,112 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 98 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 1 Number of syncs: 67 SyncTimes(ms): 46 
2016-12-26 17:59:13,117 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 98 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 1 Number of syncs: 68 SyncTimes(ms): 51 
2016-12-26 17:59:13,118 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/cloud/hadoop/dfs/name/current/edits_inprogress_0000000000000000007 -> /home/cloud/hadoop/dfs/name/current/edits_0000000000000000007-0000000000000000104
2016-12-26 17:59:13,118 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 105
2016-12-26 17:59:13,187 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 333.33 KB/s
2016-12-26 17:59:13,187 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000104 size 1578 bytes.
2016-12-26 17:59:13,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 6
2016-12-26 17:59:13,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/home/cloud/hadoop/dfs/name/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2016-12-26 17:59:32,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 18:23:42,858 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 18:23:51,548 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:51,548 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 18:23:51,548 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:51,548 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:51,548 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:51,549 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:23:56,678 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:56,678 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:56,679 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command delete is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command open is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command create is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setPermission is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command * is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command rename is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command fsck is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command mkdirs is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command setReplication is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command listStatus is: 0
2016-12-26 18:23:56,680 INFO org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager: topN size for command getfileinfo is: 0
2016-12-26 18:32:56,192 INFO BlockStateChange: BLOCK* processReport: from storage DS-ffb1f9f2-9bec-494b-b817-54ebe59834bf node DatanodeRegistration(199.60.17.227:50010, datanodeUuid=5cd60314-1f3a-47e1-81da-f01518d998ed, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-6c658c9d-ce28-4e83-b30f-1563457ab827;nsid=1575360015;c=0), blocks: 5, hasStaleStorage: false, processing time: 0 msecs
